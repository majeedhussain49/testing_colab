{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import cv2, spacy, numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.externals import joblib\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import load_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "\n",
    "def get_image_model():\n",
    "    ''' Takes the CNN weights file, and returns the VGG model update \n",
    "    with the weights. Requires the file VGG.py inside models/CNN '''\n",
    "    image_model = load_model('../saved_models/resnet34.h5')\n",
    "\n",
    "    # this is standard VGG 16 without the last two layers\n",
    "    opt = SGD(lr=1e-4, momentum=0.9)\n",
    "    image_model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "    #sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # one may experiment with \"adam\" optimizer, but the loss function for\n",
    "    # this kind of task is pretty standard\n",
    "    #image_model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    return image_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_3_input (InputLayer)   (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 8, 8, 512)         21302473  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 38,146,768\n",
      "Trainable params: 38,131,402\n",
      "Non-trainable params: 15,366\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load\n",
    "vgg16_model = get_image_model()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(image_file_name):\n",
    "    ''' Runs the given image_file to VGG 16 model and returns the \n",
    "    weights (filters) as a 1, 4096 dimension vector '''\n",
    "    #image_features \n",
    "    image_features = np.zeros((1, 7))\n",
    "    # 7> Comes from last layer of VGG Model\n",
    "\n",
    "    # Since VGG was trained as a image of 256x256, every new image\n",
    "    # is required to go through the same transformation\n",
    "    im = cv2.resize(cv2.imread(image_file_name), (256, 256))\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    im = np.reshape(im,[1,256,256,3]) \n",
    "    im = im.astype(\"float32\")/255\n",
    "\n",
    "\n",
    "   #im = im.astype(np.float32, copy=False)/255 # shape of im = (224,224,3)\n",
    "    \n",
    "  \n",
    "    #im = np.reshape(im,[1,256,256,3])\n",
    "    image_features[0,:] = vgg16_model.predict(im)[0]\n",
    "    return image_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features of dataset-No_disease\n",
      "\n",
      "Extracting Features of dataset-MDB_disease\n",
      "\n",
      "Extracting Features of dataset-Black_Measles\n",
      "\n",
      "Extracting Features of dataset-Blackrot\n",
      "\n",
      "Extracting Features of dataset-mildiou\n",
      "\n",
      "Extracting Features of dataset-Isariopsis\n",
      "\n",
      "Extracting Features of dataset-Spyder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH=os.getcwd()\n",
    "data_path = PATH + '/embed-test'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "image_features_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Extracting Features of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        image_features=get_image_features(data_path + '/'+ dataset + '/'+ img )\n",
    "        image_features_list.append(image_features)\n",
    "    \n",
    "    \n",
    "image_features_arr=np.asarray(image_features_list)\n",
    "image_features_arr = np.rollaxis(image_features_arr,1,0)\n",
    "image_features_arr = image_features_arr[0,:,:]\n",
    "\n",
    "np.savetxt('embeddings-logs/feature_vector_test_samples.txt',image_features_arr)\n",
    "#feature_vectors = np.loadtxt('feature_vectors.txt')\n",
    "pickle.dump(image_features_arr, open('embeddings-logs/feature_vector_test_samples.txt.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-No_disease\n",
      "\n",
      "Loaded the images of dataset-MDB_disease\n",
      "\n",
      "Loaded the images of dataset-Black_Measles\n",
      "\n",
      "Loaded the images of dataset-Blackrot\n",
      "\n",
      "Loaded the images of dataset-mildiou\n",
      "\n",
      "Loaded the images of dataset-Isariopsis\n",
      "\n",
      "Loaded the images of dataset-Spyder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.__version__\n",
    "\n",
    "PATH = os.getcwd()\n",
    "\n",
    "LOG_DIR = PATH+ '/embeddings-logs'\n",
    "#metadata = os.path.join(LOG_DIR, 'metadata2.tsv')\n",
    "\n",
    "#%%\n",
    "data_path = PATH + '/embed-test'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_data=[]\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(256,256))\n",
    "        img_data.append(input_img_resize)\n",
    "    \n",
    "                \n",
    "img_data = np.array(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_vectors_shape: (70, 7)\n",
      "num of images: 70\n",
      "size of individual feature vector: 7\n"
     ]
    }
   ],
   "source": [
    "feature_vectors = np.loadtxt('embeddings-logs/feature_vector_test_samples.txt')\n",
    "print (\"feature_vectors_shape:\",feature_vectors.shape)\n",
    "print (\"num of images:\",feature_vectors.shape[0])\n",
    "print (\"size of individual feature vector:\",feature_vectors.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples=feature_vectors.shape[0]\n",
    "num_of_samples_each_class = 10\n",
    "\n",
    "features = tf.Variable(feature_vectors, name='features')\n",
    "\n",
    "\n",
    "y = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "y[0:10]=0\n",
    "y[10:20]=1\n",
    "y[20:30]=2\n",
    "y[30:40]=3\n",
    "y[40:50]=4\n",
    "y[50:60]=5\n",
    "y[60:]=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =  ['No_disease','MDB_disease','Black_Measles','Blackrot','mildou','Isariopsis','Spyder']\n",
    "\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata_7_classes.tsv'), 'w')\n",
    "metadata_file.write('Class\\tName\\n')\n",
    "k=10 # num of samples in each class\n",
    "j=0\n",
    "\n",
    "for i in range(num_of_samples):\n",
    "    c = names[y[i]]\n",
    "    if i%k==0:\n",
    "        j=j+1\n",
    "    metadata_file.write('{}\\t{}\\n'.format(j,c))\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from: https://github.com/tensorflow/tensorflow/issues/6322\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "#%%\n",
    "sprite = images_to_sprite(img_data)\n",
    "cv2.imwrite(os.path.join(LOG_DIR, 'sprite_7_classes.png'), sprite)\n",
    "#scipy.misc.imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver([features])\n",
    "\n",
    "    sess.run(features.initializer)\n",
    "    saver.save(sess, os.path.join(LOG_DIR, 'images_7_classes.ckpt'))\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    # One can add multiple embeddings.\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = features.name\n",
    "    # Link this tensor to its metadata file (e.g. labels).\n",
    "    embedding.metadata_path = os.path.join(LOG_DIR, 'metadata_7_classes.tsv')\n",
    "    # Comment out if you don't want sprites\n",
    "    embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite_7_classes.png')\n",
    "    embedding.sprite.single_image_dim.extend([img_data.shape[1], img_data.shape[1]])\n",
    "    # Saves a config file that TensorBoard will read during startup.\n",
    "    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
